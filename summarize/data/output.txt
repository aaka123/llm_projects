This paper, "LONGWRITER: UNLEASHING 10,000+ WORD GENERATION FROM LONG CONTEXT LLMS," addresses the limitation of current long-context Large Language Models (LLMs) which, despite processing inputs up to 100,000 tokens, struggle to generate outputs exceeding 2,000 words.

Through controlled experiments, the authors identify that this output length limitation is primarily due to the scarcity of long-output examples in existing Supervised Fine-Tuning (SFT) datasets. The model's effective generation length is inherently bounded by the samples seen during SFT.

To overcome this, the paper introduces:
1.  **AgentWrite:** An agent-based pipeline that decomposes ultra-long generation tasks into subtasks (e.g., planning and sequential paragraph generation). This method enables off-the-shelf LLMs (like GPT-4o) to generate coherent outputs exceeding 20,000 words.
2.  **LongWriter-6k:** A new dataset containing 6,000 SFT data points with output lengths ranging from 2,000 to 32,000 words, constructed using the AgentWrite pipeline.
3.  **LongBench-Write:** A comprehensive benchmark developed to evaluate ultra-long generation capabilities, featuring diverse user writing instructions with specified output length requirements (from 0-500 words up to over 4,000 words).

By incorporating the LongWriter-6k dataset into model training, the authors successfully scaled the output length of existing models (like GLM-4-9B and Llama-3.1-8B) to over 10,000 words while maintaining output quality. Further improvement was achieved by applying Direct Preference Optimization (DPO) using both general and custom long-form preference data. Their 9B parameter model, LongWriter-9B-DPO, achieved state-of-the-art performance on the LongBench-Write benchmark, surpassing larger proprietary models.

The work concludes that existing long-context LLMs already possess the potential for larger output windows, and this capability can be unlocked by providing them with sufficient SFT data that includes extended output examples. Ablation studies confirm the critical role of the LongWriter-6k dataset and the effectiveness of DPO, while showing that methods like plan-augmented data and instruction backtranslation from low-quality long texts were less effective.